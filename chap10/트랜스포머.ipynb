{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -----------\n",
      "absl-py                 2.1.0\n",
      "asttokens               3.0.0\n",
      "astunparse              1.6.3\n",
      "backcall                0.2.0\n",
      "cachetools              5.5.0\n",
      "certifi                 2024.8.30\n",
      "charset-normalizer      3.4.0\n",
      "comm                    0.2.2\n",
      "contourpy               1.1.1\n",
      "cycler                  0.12.1\n",
      "debugpy                 1.8.9\n",
      "decorator               5.1.1\n",
      "executing               2.1.0\n",
      "fonttools               4.55.0\n",
      "gast                    0.3.3\n",
      "google-auth             2.36.0\n",
      "google-auth-oauthlib    1.0.0\n",
      "google-pasta            0.2.0\n",
      "grpcio                  1.68.1\n",
      "h5py                    2.10.0\n",
      "idna                    3.10\n",
      "importlib_metadata      8.5.0\n",
      "importlib_resources     6.4.5\n",
      "ipykernel               6.29.5\n",
      "ipython                 8.12.3\n",
      "jedi                    0.19.2\n",
      "joblib                  1.4.2\n",
      "jupyter_client          8.6.3\n",
      "jupyter_core            5.7.2\n",
      "Keras-Preprocessing     1.1.2\n",
      "kiwisolver              1.4.7\n",
      "Markdown                3.7\n",
      "MarkupSafe              2.1.5\n",
      "matplotlib              3.5.0\n",
      "matplotlib-inline       0.1.7\n",
      "nest-asyncio            1.6.0\n",
      "numpy                   1.18.5\n",
      "oauthlib                3.2.2\n",
      "opt_einsum              3.4.0\n",
      "packaging               24.2\n",
      "pandas                  2.0.3\n",
      "parso                   0.8.4\n",
      "pexpect                 4.9.0\n",
      "pickleshare             0.7.5\n",
      "pillow                  10.4.0\n",
      "pip                     24.3.1\n",
      "platformdirs            4.3.6\n",
      "prompt_toolkit          3.0.48\n",
      "protobuf                3.20.3\n",
      "psutil                  6.1.0\n",
      "ptyprocess              0.7.0\n",
      "pure_eval               0.2.3\n",
      "pyasn1                  0.6.1\n",
      "pyasn1_modules          0.4.1\n",
      "Pygments                2.18.0\n",
      "pyparsing               3.1.4\n",
      "python-dateutil         2.9.0.post0\n",
      "pytz                    2024.2\n",
      "pyzmq                   26.2.0\n",
      "requests                2.32.3\n",
      "requests-oauthlib       2.0.0\n",
      "rsa                     4.9\n",
      "scikit-learn            1.3.2\n",
      "scipy                   1.4.1\n",
      "seaborn                 0.13.2\n",
      "setuptools              56.0.0\n",
      "six                     1.16.0\n",
      "stack-data              0.6.3\n",
      "tensorboard             2.14.0\n",
      "tensorboard-data-server 0.7.2\n",
      "tensorflow              2.3.0\n",
      "tensorflow-estimator    2.3.0\n",
      "tensorflow-gpu          2.3.0\n",
      "termcolor               2.4.0\n",
      "threadpoolctl           3.5.0\n",
      "tornado                 6.4.2\n",
      "traitlets               5.14.3\n",
      "typing_extensions       4.12.2\n",
      "tzdata                  2024.2\n",
      "urllib3                 2.2.3\n",
      "wcwidth                 0.2.13\n",
      "Werkzeug                3.0.6\n",
      "wheel                   0.45.1\n",
      "wrapt                   1.17.0\n",
      "zipp                    3.20.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://matplotlib.org/devdocs/devel/min_dep_policy.html#list-of-dependency-versions\n",
    "\n",
    "버전 맞추기!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 03:21:24.496575: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2024-12-03 03:21:24.496609: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# 코드 10-25 라이브러리 호출\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-26 데이터셋 전처리 함수 정의\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())  # 소문자로 전환\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)  # 특수 문자 제거\n",
    "    # 단어와 그 뒤에 오는 구두점 사이에 공백을 삽입(예 “she is here.” → “she is here . ”)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # a-z, A-Z, ., ?, ! 등을 제외하고 모두 공백으로 바꿈\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.rstrip().strip()  # 공백 문자 제거\n",
    "    # 문장의 시작 <start>와 종료 <end> 토큰 생성(모델이 예측을 시작하고 종료할 시기를 알 수 있도록 시작과 끝을 지정)\n",
    "    w = \"<start> \" + w + \" <end>\"\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "# 코드 10-27 데이터 전처리 확인\n",
    "en_sentence = \"May I borrow this book?\"\n",
    "sp_sentence = \"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-28 [ENGLISH, SPANISH] 형식의 단어 반환\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding=\"UTF-8\").read().strip().split(\"\\n\")\n",
    "\n",
    "    word_pairs = [\n",
    "        [preprocess_sentence(w) for w in l.split(\"\\t\")] for l in lines[:num_examples]\n",
    "    ]\n",
    "\n",
    "    return zip(*word_pairs)\n",
    "\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "\n",
    "def tokenize(lang):  # 문장의 토큰화\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\")\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding=\"post\")\n",
    "\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "\n",
    "def load_dataset(path, num_examples=None):  # 입력/출력(english, spanish) 쌍 만들기\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-29 데이터셋 크기 조정\n",
    "num_examples = 30000  # 다양한 세트로 수행해 보는 것도 좋습니다.\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(\n",
    "    \"data/spa.txt\", num_examples\n",
    ")\n",
    "\n",
    "# 대상 텐서의 최대 길이(max_length) 계산\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "\n",
    "# 8:2 비율로 훈련과 검증\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = (\n",
    "    train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 03:23:00.573788: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-12-03 03:23:00.792830: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:968] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-03 03:23:00.792864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:0a:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.759GHz coreCount: 20 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2024-12-03 03:23:00.792927: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2024-12-03 03:23:00.792983: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-03 03:23:00.793025: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-03 03:23:00.793066: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-03 03:23:00.793132: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-03 03:23:00.793180: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-03 03:23:00.793220: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2024-12-03 03:23:00.793225: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-12-03 03:23:00.793831: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-03 03:23:00.798640: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3800105000 Hz\n",
      "2024-12-03 03:23:00.800155: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d483f60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-03 03:23:00.800167: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-12-03 03:23:00.801214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-12-03 03:23:00.801224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \n"
     ]
    }
   ],
   "source": [
    "# 코드 10-30 하이퍼파라미터 초기화\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "\n",
    "# 데이터 분석을 위한 데이터셋 분리\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (input_tensor_train, target_tensor_train)\n",
    ").shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-31 인코더 네트워크 구축\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        # 7장에서 학습했던 GRU를 이용한 모델 생성\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.enc_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer=\"glorot_uniform\",\n",
    "        )\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))  # 은닉층 초기화\n",
    "\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-32 어텐션 구축\n",
    "class EDAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(EDAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        # 어텐션 가중치(attention_weights)의 형태는 (배치 크기, 시퀀스 최대 길이, 1)이 됩니다.\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        # 컨텍스트 벡터(context_vector)의 형태는 (배치 크기, 은닉층 크기)입니다.\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "attention_layer = EDAttention(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-33 디코더 네트워크 구축\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.dec_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer=\"glorot_uniform\",\n",
    "        )\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = EDAttention(self.dec_units)  # 어텐션 적용\n",
    "\n",
    "    # 인코더 출력(enc_output) 형태는 (배치 크기, 시퀀스 최대 길이, 은닉층 크기)입니다.\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        # 임베딩층을 통과한 후 x의 형태는 (배치 크기, 1, 임베딩 차원)입니다.\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)  # 병합된 벡터를 GRU로 보냅니다.\n",
    "        # 출력 형태는 (배치 크기×1, 은닉층 크기)입니다.\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights\n",
    "\n",
    "\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-34 옵티마이저 및 손실 함수 정의\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-35 체크포인트 설정\n",
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    optimizer=optimizer,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-36 모델 훈련 함수 정의\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index[\"<start>\"]] * BATCH_SIZE, 1)\n",
    "        for t in range(1, targ.shape[1]):  # 대상 단어를 입력으로 사용\n",
    "            # 인코더 출력(enc_output)을 디코더로 보냅니다.\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = loss / int(targ.shape[1])  # 손실/오차 계산\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.2050\n",
      "Epoch 1 Loss 3.0764\n",
      "Epoch 2 Batch 0 Loss 2.3529\n",
      "Epoch 2 Loss 2.1971\n",
      "Epoch 3 Batch 0 Loss 2.0993\n",
      "Epoch 3 Loss 1.9473\n",
      "Epoch 4 Batch 0 Loss 1.7938\n",
      "Epoch 4 Loss 1.7816\n",
      "Epoch 5 Batch 0 Loss 1.6978\n",
      "Epoch 5 Loss 1.6757\n",
      "Epoch 6 Batch 0 Loss 1.5791\n",
      "Epoch 6 Loss 1.5596\n",
      "Epoch 7 Batch 0 Loss 1.5519\n",
      "Epoch 7 Loss 1.4088\n",
      "Epoch 8 Batch 0 Loss 1.2836\n",
      "Epoch 8 Loss 1.2802\n",
      "Epoch 9 Batch 0 Loss 1.1336\n",
      "Epoch 9 Loss 1.1653\n",
      "Epoch 10 Batch 0 Loss 1.0387\n",
      "Epoch 10 Loss 1.0852\n",
      "Time taken for 1 epoch 8.933491468429565 sec\n"
     ]
    }
   ],
   "source": [
    "# 코드 10-37 모델 훈련\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch, (inp, targ) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 2 == 0:  # 2 에포크마다 모델을 체크포인트에 저장\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}\")\n",
    "\n",
    "print(f\"Time taken for 1 epoch {time.time()-start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-38 모델 평가 및 시각화를 위한 함수\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(\" \")]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [inputs], maxlen=max_length_inp, padding=\"post\"\n",
    "    )\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = \"\"\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index[\"<start>\"]], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(\n",
    "            dec_input, dec_hidden, enc_out\n",
    "        )\n",
    "        attention_weights = tf.reshape(attention_weights, (-1,))  # 어텐션 가중치\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + \" \"\n",
    "        if targ_lang.index_word[predicted_id] == \"<end>\":\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims(\n",
    "            [predicted_id], 0\n",
    "        )  # 예측된 ID가 모델에 피드백됩니다.\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-39 어텐션 가중치 시각화 함수\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap=\"viridis\")\n",
    "\n",
    "    fontdict = {\"fontsize\": 14}\n",
    "\n",
    "    ax.set_xticklabels([\"\"] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([\"\"] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: i m a seat . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_291575/2557474208.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([\"\"] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_291575/2557474208.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([\"\"] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 코드 10-40 번역을 위한 함수 정의 및 번역 문장 입력 함수\n",
    "import numpy as np\n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print(\"Input: %s\" % (sentence))\n",
    "    print(\"Predicted translation: {}\".format(result))\n",
    "\n",
    "    attention_plot = attention_plot[\n",
    "        : len(result.split(\" \")), : len(sentence.split(\" \"))\n",
    "    ]\n",
    "    plot_attention(\n",
    "        attention_plot, sentence.split(\" \"), result.split(\" \")\n",
    "    )  # 어텐션 가중치 매핑\n",
    "\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "translate(\"esta es mi vida.\")  # 스페인어를 영어로 번역"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
