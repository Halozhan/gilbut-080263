{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 11:57:50.788546: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2024-12-03 11:57:50.788585: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# 코드 10-25 라이브러리 호출\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-26 데이터셋 전처리 함수 정의\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())  # 소문자로 전환\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)  # 특수 문자 제거\n",
    "    # 단어와 그 뒤에 오는 구두점 사이에 공백을 삽입(예 “she is here.” → “she is here . ”)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # a-z, A-Z, ., ?, ! 등을 제외하고 모두 공백으로 바꿈\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.rstrip().strip()  # 공백 문자 제거\n",
    "    # 문장의 시작 <start>와 종료 <end> 토큰 생성(모델이 예측을 시작하고 종료할 시기를 알 수 있도록 시작과 끝을 지정)\n",
    "    w = \"<start> \" + w + \" <end>\"\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "# 코드 10-27 데이터 전처리 확인\n",
    "en_sentence = \"May I borrow this book?\"\n",
    "sp_sentence = \"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-28 [ENGLISH, SPANISH] 형식의 단어 반환\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding=\"UTF-8\").read().strip().split(\"\\n\")\n",
    "\n",
    "    word_pairs = [\n",
    "        [preprocess_sentence(w) for w in l.split(\"\\t\")] for l in lines[:num_examples]\n",
    "    ]\n",
    "\n",
    "    return zip(*word_pairs)\n",
    "\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "\n",
    "def tokenize(lang):  # 문장의 토큰화\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\")\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding=\"post\")\n",
    "\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "\n",
    "def load_dataset(path, num_examples=None):  # 입력/출력(english, spanish) 쌍 만들기\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-29 데이터셋 크기 조정\n",
    "num_examples = 30000  # 다양한 세트로 수행해 보는 것도 좋습니다.\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(\n",
    "    \"data/spa.txt\", num_examples\n",
    ")\n",
    "\n",
    "# 대상 텐서의 최대 길이(max_length) 계산\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "\n",
    "# 8:2 비율로 훈련과 검증\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = (\n",
    "    train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 11:57:52.949660: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2024-12-03 11:57:53.103439: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:968] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-03 11:57:53.103470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:0a:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.759GHz coreCount: 20 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2024-12-03 11:57:53.103538: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2024-12-03 11:57:53.103590: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-03 11:57:53.103631: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-03 11:57:53.103671: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-03 11:57:53.103722: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-03 11:57:53.103764: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-03 11:57:53.103800: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2024-12-03 11:57:53.103805: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-12-03 11:57:53.105065: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-03 11:57:53.113931: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3800105000 Hz\n",
      "2024-12-03 11:57:53.115239: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19239ef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-03 11:57:53.115251: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-12-03 11:57:53.116449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-12-03 11:57:53.116460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \n"
     ]
    }
   ],
   "source": [
    "# 코드 10-30 하이퍼파라미터 초기화\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "\n",
    "# 데이터 분석을 위한 데이터셋 분리\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (input_tensor_train, target_tensor_train)\n",
    ").shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-31 인코더 네트워크 구축\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        # 7장에서 학습했던 GRU를 이용한 모델 생성\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.enc_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer=\"glorot_uniform\",\n",
    "        )\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))  # 은닉층 초기화\n",
    "\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-32 어텐션 구축\n",
    "class EDAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(EDAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        # 어텐션 가중치(attention_weights)의 형태는 (배치 크기, 시퀀스 최대 길이, 1)이 됩니다.\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        # 컨텍스트 벡터(context_vector)의 형태는 (배치 크기, 은닉층 크기)입니다.\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "attention_layer = EDAttention(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-33 디코더 네트워크 구축\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.dec_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer=\"glorot_uniform\",\n",
    "        )\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = EDAttention(self.dec_units)  # 어텐션 적용\n",
    "\n",
    "    # 인코더 출력(enc_output) 형태는 (배치 크기, 시퀀스 최대 길이, 은닉층 크기)입니다.\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        # 임베딩층을 통과한 후 x의 형태는 (배치 크기, 1, 임베딩 차원)입니다.\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)  # 병합된 벡터를 GRU로 보냅니다.\n",
    "        # 출력 형태는 (배치 크기×1, 은닉층 크기)입니다.\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights\n",
    "\n",
    "\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-34 옵티마이저 및 손실 함수 정의\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-35 체크포인트 설정\n",
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    optimizer=optimizer,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-36 모델 훈련 함수 정의\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index[\"<start>\"]] * BATCH_SIZE, 1)\n",
    "        for t in range(1, targ.shape[1]):  # 대상 단어를 입력으로 사용\n",
    "            # 인코더 출력(enc_output)을 디코더로 보냅니다.\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = loss / int(targ.shape[1])  # 손실/오차 계산\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.5420\n",
      "Epoch 1 Batch 100 Loss 2.2810\n",
      "Epoch 1 Batch 200 Loss 1.7662\n",
      "Epoch 1 Batch 300 Loss 1.6393\n",
      "Epoch 1 Loss 2.0463\n",
      "Epoch 2 Batch 0 Loss 1.6065\n",
      "Epoch 2 Batch 100 Loss 1.4443\n",
      "Epoch 2 Batch 200 Loss 1.4452\n",
      "Epoch 2 Batch 300 Loss 1.3314\n",
      "Epoch 2 Loss 1.4041\n",
      "Epoch 3 Batch 0 Loss 1.0169\n",
      "Epoch 3 Batch 100 Loss 1.0833\n",
      "Epoch 3 Batch 200 Loss 1.0142\n",
      "Epoch 3 Batch 300 Loss 0.9419\n",
      "Epoch 3 Loss 0.9901\n",
      "Epoch 4 Batch 0 Loss 0.7444\n",
      "Epoch 4 Batch 100 Loss 0.6667\n",
      "Epoch 4 Batch 200 Loss 0.6123\n",
      "Epoch 4 Batch 300 Loss 0.7073\n",
      "Epoch 4 Loss 0.6742\n",
      "Epoch 5 Batch 0 Loss 0.4340\n",
      "Epoch 5 Batch 100 Loss 0.4460\n",
      "Epoch 5 Batch 200 Loss 0.4910\n",
      "Epoch 5 Batch 300 Loss 0.5144\n",
      "Epoch 5 Loss 0.4594\n",
      "Epoch 6 Batch 0 Loss 0.2921\n",
      "Epoch 6 Batch 100 Loss 0.2937\n",
      "Epoch 6 Batch 200 Loss 0.3131\n",
      "Epoch 6 Batch 300 Loss 0.2570\n",
      "Epoch 6 Loss 0.3182\n",
      "Epoch 7 Batch 0 Loss 0.1973\n",
      "Epoch 7 Batch 100 Loss 0.1899\n",
      "Epoch 7 Batch 200 Loss 0.2280\n",
      "Epoch 7 Batch 300 Loss 0.2271\n",
      "Epoch 7 Loss 0.2266\n",
      "Epoch 8 Batch 0 Loss 0.1659\n",
      "Epoch 8 Batch 100 Loss 0.1748\n",
      "Epoch 8 Batch 200 Loss 0.1509\n",
      "Epoch 8 Batch 300 Loss 0.2084\n",
      "Epoch 8 Loss 0.1691\n",
      "Epoch 9 Batch 0 Loss 0.1069\n",
      "Epoch 9 Batch 100 Loss 0.1137\n",
      "Epoch 9 Batch 200 Loss 0.1591\n",
      "Epoch 9 Batch 300 Loss 0.1024\n",
      "Epoch 9 Loss 0.1304\n",
      "Epoch 10 Batch 0 Loss 0.1264\n",
      "Epoch 10 Batch 100 Loss 0.0688\n",
      "Epoch 10 Batch 200 Loss 0.0997\n",
      "Epoch 10 Batch 300 Loss 0.1139\n",
      "Epoch 10 Loss 0.1069\n",
      "Time taken for 1 epoch 244.4111466407776 sec\n"
     ]
    }
   ],
   "source": [
    "# 코드 10-37 모델 훈련\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch, (inp, targ) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 2 == 0:  # 2 에포크마다 모델을 체크포인트에 저장\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}\")\n",
    "\n",
    "print(f\"Time taken for 1 epoch {time.time()-start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-38 모델 평가 및 시각화를 위한 함수\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(\" \")]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [inputs], maxlen=max_length_inp, padding=\"post\"\n",
    "    )\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = \"\"\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index[\"<start>\"]], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(\n",
    "            dec_input, dec_hidden, enc_out\n",
    "        )\n",
    "        attention_weights = tf.reshape(attention_weights, (-1,))  # 어텐션 가중치\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + \" \"\n",
    "        if targ_lang.index_word[predicted_id] == \"<end>\":\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims(\n",
    "            [predicted_id], 0\n",
    "        )  # 예측된 ID가 모델에 피드백됩니다.\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 10-39 어텐션 가중치 시각화 함수\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap=\"viridis\")\n",
    "\n",
    "    fontdict = {\"fontsize\": 14}\n",
    "\n",
    "    ax.set_xticklabels([\"\"] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([\"\"] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: this is my life . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_807500/2557474208.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([\"\"] + sentence, fontdict=fontdict, rotation=90)\n",
      "/tmp/ipykernel_807500/2557474208.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([\"\"] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 코드 10-40 번역을 위한 함수 정의 및 번역 문장 입력 함수\n",
    "import numpy as np\n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print(\"Input: %s\" % (sentence))\n",
    "    print(\"Predicted translation: {}\".format(result))\n",
    "\n",
    "    attention_plot = attention_plot[\n",
    "        : len(result.split(\" \")), : len(sentence.split(\" \"))\n",
    "    ]\n",
    "    plot_attention(\n",
    "        attention_plot, sentence.split(\" \"), result.split(\" \")\n",
    "    )  # 어텐션 가중치 매핑\n",
    "\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "translate(\"esta es mi vida.\")  # 스페인어를 영어로 번역"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
