{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 01:39:13.879335: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733157553.893165  104674 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733157553.897595  104674 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# 코드 7-3 라이브러리 호출\n",
    "import os  # 운영 체제의 모듈을 가져옵니다.\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = (\n",
    "    \"2\"  # 케라스에서 발생하는 경고(warning) 메시지를 제거합니다.\n",
    ")\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-4 값 초기화\n",
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "assert tf.__version__.startswith(\"2.\")  # 텐서플로 버전이 2임을 확인\n",
    "\n",
    "batch_size = 128\n",
    "total_words = 10000\n",
    "max_review_len = 80\n",
    "embedding_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_shape: (25000, 80) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "x_test_shape: (25000, 80)\n",
      "(128, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1733157565.993213  104674 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# 코드 7-5 데이터셋 준비\n",
    "# IMDB 데이터셋을 로드하고, 단어 수를 제한합니다.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(\n",
    "    num_words=total_words\n",
    ")\n",
    "# 시퀀스 길이를 max_review_len으로 패딩합니다.\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
    "\n",
    "# 훈련 데이터셋을 변환합니다.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.shuffle(10000).batch(batch_size, drop_remainder=True)\n",
    "# 테스트 데이터셋을 변환합니다.\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_data = test_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "# 데이터셋의 형태를 출력합니다.\n",
    "print(\"x_train_shape:\", x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))\n",
    "print(\"x_test_shape:\", x_test.shape)\n",
    "\n",
    "# 테스트 데이터셋의 샘플을 출력합니다.\n",
    "sample = next(iter(test_data))\n",
    "print(sample[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-6 RNN 셀을 이용한 네트워크 생성\n",
    "class RNN_Build(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(RNN_Build, self).__init__()\n",
    "\n",
    "        self.units = units\n",
    "        self.embedding = layers.Embedding(\n",
    "            total_words, embedding_len, input_length=max_review_len\n",
    "        )\n",
    "        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=0.2)\n",
    "        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.2)\n",
    "        self.outlayer = layers.Dense(1)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.embedding(inputs)  # 입력 데이터에 원-핫 인코딩 적용\n",
    "        state0 = tf.zeros([inputs.shape[0], self.units])\n",
    "        state1 = tf.zeros([inputs.shape[0], self.units])\n",
    "        for word in tf.unstack(x, axis=1):\n",
    "            # out0, state0 각각에 self.RNNCell0에서 받아 온 값을 저장\n",
    "            out0, state0 = self.rnn_cell0(word, [state0], training=training)\n",
    "            # out1, state1 각각에 self.RNNCell1에서 받아 온 값을 저장\n",
    "            out1, state1 = self.rnn_cell1(out0, [state1], training=training)\n",
    "        # 출력층 out1을 적용한 후 그 값을 x 변수에 저장\n",
    "        x = self.outlayer(out1)\n",
    "        # 마지막으로 x에 시그모이드 활성화 함수를 적용하여 prob에 저장\n",
    "        prob = tf.sigmoid(x)\n",
    "        return prob\n",
    "        # return tf.squeeze(prob)  # prob 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halozhan/Study/.venv/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(128,), output.shape=(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 128, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m RNN_Build(units)\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mAdam(\u001b[38;5;241m0.001\u001b[39m),\n\u001b[1;32m     11\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     12\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# experimental_run_tf_function=False,\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Study/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Study/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:737\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m    734\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(output)\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m--> 737\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    738\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    739\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    740\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    741\u001b[0m     )\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(128,), output.shape=(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 128, 1)"
     ]
    }
   ],
   "source": [
    "# 코드 7-7 모델 훈련\n",
    "import time\n",
    "\n",
    "units = 64\n",
    "epochs = 4\n",
    "t0 = time.time()  # 모형의 실행 시간을 위해 시간을 t0에 저장\n",
    "\n",
    "model = RNN_Build(units)\n",
    "model.compile(\n",
    "    optimizer=Adam(0.001),\n",
    "    loss=tf.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"],\n",
    "    # experimental_run_tf_function=False,\n",
    ")\n",
    "\n",
    "model.fit(train_data, epochs=epochs, validation_data=test_data, validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.5976 - loss: 0.6162\n",
      "Epoch 2/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.8605 - loss: 0.3244 - val_accuracy: 0.8285 - val_loss: 0.3797\n",
      "Epoch 3/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9210 - loss: 0.1995\n",
      "Epoch 4/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9627 - loss: 0.1079 - val_accuracy: 0.8219 - val_loss: 0.5517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f487a11a020>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN 셀 대신 RNN 레이어를 사용한 코드\n",
    "\n",
    "# 코드 7-6 RNN 셀을 이용한 네트워크 생성\n",
    "class RNN_Build(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(RNN_Build, self).__init__()\n",
    "\n",
    "        self.units = units\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len, input_length=max_review_len)\n",
    "        self.rnn = layers.SimpleRNN(units, return_sequences=False, return_state=False, dropout=0.2)\n",
    "        self.outlayer = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.rnn(x, training=training)\n",
    "        x = self.outlayer(x)\n",
    "        return x\n",
    "\n",
    "# 코드 7-7 모델 훈련\n",
    "import time\n",
    "\n",
    "units = 64\n",
    "epochs = 4\n",
    "t0 = time.time()  # 모형의 실행 시간을 위해 시간을 t0에 저장\n",
    "\n",
    "model = RNN_Build(units)\n",
    "model.compile(\n",
    "    optimizer=Adam(0.001),\n",
    "    loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    "    # experimental_run_tf_function=False,\n",
    ")\n",
    "\n",
    "model.fit(train_data, epochs=epochs, validation_data=test_data, validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 평가...\n",
      "loss=0.0317, accuracy: 99.2708%\n",
      "테스트 데이터셋 평가...\n",
      "loss=0.5517, accuracy: 82.1875%\n",
      "시간: 27.626402139663696\n"
     ]
    }
   ],
   "source": [
    "# 코드 7-8 모델 평가\n",
    "print(\"훈련 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(train_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "print(\"테스트 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(test_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "t1 = time.time()\n",
    "print(\"시간:\", t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-9 네트워크(신경망) 구축\n",
    "class RNN_Build(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(RNN_Build, self).__init__()\n",
    "        self.embedding = layers.Embedding(\n",
    "            total_words, embedding_len, input_length=max_review_len\n",
    "        )\n",
    "\n",
    "        self.rnn = Sequential(\n",
    "            [\n",
    "                layers.SimpleRNN(units, dropout=0.5, return_sequences=True),\n",
    "                layers.SimpleRNN(units, dropout=0.5),\n",
    "            ]\n",
    "        )\n",
    "        self.outlayer = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        x = self.embedding(x)\n",
    "        x = self.rnn(x)\n",
    "        x = self.outlayer(x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.6335 - loss: 0.6169\n",
      "Epoch 2/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - accuracy: 0.8430 - loss: 0.3661 - val_accuracy: 0.8347 - val_loss: 0.3908\n",
      "Epoch 3/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.8785 - loss: 0.3037\n",
      "Epoch 4/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.8997 - loss: 0.2547 - val_accuracy: 0.8235 - val_loss: 0.4910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f487601ad40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드 7-10 모델 훈련\n",
    "import time\n",
    "\n",
    "units = 64\n",
    "epochs = 4\n",
    "t0 = time.time()\n",
    "\n",
    "model = RNN_Build(units)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    "    # experimental_run_tf_function=False,\n",
    ")\n",
    "\n",
    "model.fit(train_data, epochs=epochs, validation_data=test_data, validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 평가...\n",
      "loss=0.1444, accuracy: 94.4792%\n",
      "테스트 데이터셋 평가...\n",
      "loss=0.4910, accuracy: 82.3518%\n",
      "시간: 31.28188180923462\n"
     ]
    }
   ],
   "source": [
    "# 코드 7-11 모델 평가\n",
    "print(\"훈련 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(train_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "print(\"테스트 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(test_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"시간:\", t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-12 네트워크 생성\n",
    "class LSTM_Build(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(LSTM_Build, self).__init__()\n",
    "\n",
    "        # 임베딩 계층\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            total_words, embedding_len, input_length=max_review_len\n",
    "        )\n",
    "\n",
    "        # LSTM 계층\n",
    "        self.lstm0 = tf.keras.layers.LSTM(units, return_sequences=True, dropout=0.5)\n",
    "        self.lstm1 = tf.keras.layers.LSTM(units, return_sequences=False, dropout=0.5)\n",
    "\n",
    "        # 출력 계층\n",
    "        self.outlayer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # 임베딩 처리\n",
    "        x = self.embedding(inputs)\n",
    "\n",
    "        # 첫 번째 LSTM 계층\n",
    "        x = self.lstm0(x, training=training)\n",
    "\n",
    "        # 두 번째 LSTM 계층\n",
    "        x = self.lstm1(x, training=training)\n",
    "\n",
    "        # 출력 계층을 통과\n",
    "        x = self.outlayer(x)\n",
    "\n",
    "        # 시그모이드 확률 출력\n",
    "        prob = tf.sigmoid(x)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 82ms/step - accuracy: 0.6403 - loss: 0.5904\n",
      "Epoch 2/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 116ms/step - accuracy: 0.8666 - loss: 0.3233 - val_accuracy: 0.8385 - val_loss: 0.3707\n",
      "Epoch 3/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 80ms/step - accuracy: 0.8984 - loss: 0.2575\n",
      "Epoch 4/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 114ms/step - accuracy: 0.9200 - loss: 0.2121 - val_accuracy: 0.8342 - val_loss: 0.4054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f48757ec400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드 7-13 모델 훈련\n",
    "import time\n",
    "\n",
    "units = 64\n",
    "epochs = 4\n",
    "t0 = time.time()\n",
    "\n",
    "model = LSTM_Build(units)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    "    #   experimental_run_tf_function=False,\n",
    ")\n",
    "\n",
    "model.fit(train_data, epochs=epochs, validation_data=test_data, validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 평가...\n",
      "loss=0.1418, accuracy: 95.1923%\n",
      "테스트 데이터셋 평가...\n",
      "loss=0.4054, accuracy: 83.4175%\n",
      "시간: 91.17441725730896\n"
     ]
    }
   ],
   "source": [
    "# 코드 7-14 모델 평가\n",
    "print(\"훈련 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(train_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\n",
    "print(\"테스트 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(test_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\n",
    "t1 = time.time()\n",
    "print('시간:', t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-15 네트워크 생성\n",
    "class LSTM_Build(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(LSTM_Build, self).__init__()\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            total_words, embedding_len, input_length=max_review_len\n",
    "        )\n",
    "        self.rnn = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.LSTM(\n",
    "                    units, dropout=0.5, return_sequences=True, unroll=True\n",
    "                ),\n",
    "                tf.keras.layers.LSTM(units, dropout=0.5, unroll=True),\n",
    "            ]\n",
    "        )\n",
    "        self.outlayer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        x = self.embedding(x)\n",
    "        x = self.rnn(x)\n",
    "        x = self.outlayer(x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 79ms/step - accuracy: 0.6629 - loss: 0.5801\n",
      "Epoch 2/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 115ms/step - accuracy: 0.8631 - loss: 0.3276 - val_accuracy: 0.8412 - val_loss: 0.3619\n",
      "Epoch 3/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - accuracy: 0.8978 - loss: 0.2577\n",
      "Epoch 4/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 105ms/step - accuracy: 0.9159 - loss: 0.2166 - val_accuracy: 0.8329 - val_loss: 0.3934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4872d461a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드 7-16 모델 훈련\n",
    "import time\n",
    "\n",
    "units = 64\n",
    "epochs = 4\n",
    "t0 = time.time()\n",
    "\n",
    "model = LSTM_Build(units)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    "    # experimental_run_tf_function=False,\n",
    ")\n",
    "\n",
    "model.fit(train_data, epochs=epochs, validation_data=test_data, validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 평가...\n",
      "loss=0.1556, accuracy: 95.1402%\n",
      "테스트 데이터셋 평가...\n",
      "loss=0.3934, accuracy: 83.2893%\n",
      "시간: 94.14238786697388\n"
     ]
    }
   ],
   "source": [
    "# 코드 7-17 모델 평가\n",
    "print(\"훈련 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(train_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "print(\"테스트 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(test_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"시간:\", t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-18 네트워크 생성\n",
    "class GRU_Build(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(GRU_Build, self).__init__()\n",
    "\n",
    "        self.state0 = [tf.zeros([batch_size, units])]\n",
    "        self.state1 = [tf.zeros([batch_size, units])]\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            total_words, embedding_len, input_length=max_review_len\n",
    "        )\n",
    "        self.RNNCell0 = tf.keras.layers.GRUCell(units, dropout=0.5)\n",
    "        self.RNNCell1 = tf.keras.layers.GRUCell(units, dropout=0.5)\n",
    "        self.outlayer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        x = self.embedding(x)\n",
    "        state0 = self.state0  # 초기 상태는 모두 0으로 설정\n",
    "        state1 = self.state1\n",
    "        for word in tf.unstack(x, axis=1):\n",
    "            out0, state0 = self.RNNCell0(word, state0, training)\n",
    "            out1, state1 = self.RNNCell1(out0, state1, training)\n",
    "\n",
    "        x = self.outlayer(out1)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-18 네트워크 생성\n",
    "class GRU_Build(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(GRU_Build, self).__init__()\n",
    "\n",
    "        self.state0 = [tf.zeros([batch_size, units])]\n",
    "        self.state1 = [tf.zeros([batch_size, units])]\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            total_words, embedding_len, input_length=max_review_len\n",
    "        )\n",
    "        self.RNN0 = tf.keras.layers.RNN(tf.keras.layers.GRUCell(units, dropout=0.5), return_sequences=True, return_state=True)\n",
    "        self.RNN1 = tf.keras.layers.RNN(tf.keras.layers.GRUCell(units, dropout=0.5), return_sequences=False, return_state=True)\n",
    "        self.outlayer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        x = self.embedding(x)\n",
    "        x, state0 = self.RNN0(x, initial_state=self.state0, training=training)\n",
    "        x, state1 = self.RNN1(x, initial_state=self.state1, training=training)\n",
    "\n",
    "        x = self.outlayer(x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 76ms/step - accuracy: 0.6205 - loss: 0.6150\n",
      "Epoch 2/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 110ms/step - accuracy: 0.8583 - loss: 0.3332 - val_accuracy: 0.8438 - val_loss: 0.3576\n",
      "Epoch 3/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.8916 - loss: 0.2726\n",
      "Epoch 4/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 108ms/step - accuracy: 0.9161 - loss: 0.2207 - val_accuracy: 0.8393 - val_loss: 0.3943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f482045a320>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드 7-19 모델 훈련\n",
    "import time\n",
    "\n",
    "units = 64\n",
    "epochs = 4\n",
    "t0 = time.time()\n",
    "\n",
    "model = GRU_Build(units)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    "    # experimental_run_tf_function=False,\n",
    ")\n",
    "\n",
    "model.fit(train_data, epochs=epochs, validation_data=test_data, validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 평가...\n",
      "loss=0.1495, accuracy: 95.1282%\n",
      "테스트 데이터셋 평가...\n",
      "loss=0.3943, accuracy: 83.9343%\n",
      "시간: 86.69557738304138\n"
     ]
    }
   ],
   "source": [
    "# 코드 7-20 모델 평가\n",
    "print(\"훈련 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(train_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "print(\"테스트 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(test_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "t1 = time.time()\n",
    "print(\"시간:\", t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 7-21 네트워크 생성\n",
    "\n",
    "\n",
    "class GRU_Build(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(GRU_Build, self).__init__()\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            total_words, embedding_len, input_length=max_review_len\n",
    "        )\n",
    "        self.rnn = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.GRU(\n",
    "                    units, dropout=0.5, return_sequences=True, unroll=True\n",
    "                ),\n",
    "                tf.keras.layers.GRU(units, dropout=0.5, unroll=True),\n",
    "            ]\n",
    "        )\n",
    "        self.outlayer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        x = self.embedding(x)\n",
    "        x = self.rnn(x)\n",
    "        x = self.outlayer(x)\n",
    "        prob = tf.sigmoid(x)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 74ms/step - accuracy: 0.6393 - loss: 0.6042\n",
      "Epoch 2/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 151ms/step - accuracy: 0.8672 - loss: 0.3212 - val_accuracy: 0.8386 - val_loss: 0.3613\n",
      "Epoch 3/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 93ms/step - accuracy: 0.8949 - loss: 0.2666\n",
      "Epoch 4/4\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 135ms/step - accuracy: 0.9158 - loss: 0.2236 - val_accuracy: 0.8329 - val_loss: 0.3882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f486de5c490>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드 7-22 모델 훈련\n",
    "import time\n",
    "\n",
    "units = 64\n",
    "epochs = 4\n",
    "t0 = time.time()\n",
    "\n",
    "model = GRU_Build(units)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    "    # experimental_run_tf_function=False,\n",
    ")\n",
    "\n",
    "model.fit(train_data, epochs=epochs, validation_data=test_data, validation_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 평가...\n",
      "loss=0.1623, accuracy: 94.7837%\n",
      "테스트 데이터셋 평가...\n",
      "loss=0.3882, accuracy: 83.2933%\n",
      "시간: 118.12830471992493\n"
     ]
    }
   ],
   "source": [
    "# 코드 7-23 모델 평가\n",
    "print(\"훈련 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(train_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "print(\"테스트 데이터셋 평가...\")\n",
    "(loss, accuracy) = model.evaluate(test_data, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"시간:\", t1 - t0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
